{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seafood.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrVqzh1uXUqX"
      },
      "source": [
        "작성자: 김승철\n",
        "이메일: cheul1987@gmail.com\n",
        "\n",
        "현 스크립트는 2021년 빅콘테스트 수산Biz 데이터를 활용하여 수산물 단가 예측을 하기위해 작성되었습니다. 오리지날 버젼은 seafood.py 파일로, 참가자 개인 PC로 진행되었으며, 구글 코랩의 경우 원활한 진행(상대적 저스펙)을 위해 코드를 간략화 하여 결과 보고서 내용이 아주 미세하게 일부 다를 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PzRNHmMhDGh"
      },
      "source": [
        "# 데이터 활용 현황\n",
        "- 트레이닝 세트 (Training set)\n",
        "  - 2021빅콘테스트_데이터분석분야_챔피언리그_수산Biz_문제데이터\n",
        "  - 트레이닝 세트의 20%를 검증 세트(Validation set)로 사용 (교차 검증 활용)\n",
        "- 테스트 세트1 (Test set1)\n",
        "  - 2021빅콘테스트_데이터분석분야_챔피언리그_수산Biz_자율평가데이터\n",
        "  - 테스트 세트2 예측단가 예상 시, 추가 트레이닝 세트로 활용\n",
        "- 테스트 세트2 (Test set2)\n",
        "  - 2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_평가데이터\n",
        "  - 주요 특징(Feature)들이 생략되어 있어 예측단가 측정 차이 클 것으로 예상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvM7KV_3XimN"
      },
      "source": [
        "## 테스트 세트1 분석 모델 수립\n",
        "- 데이터: 트레이닝 세트와 테스트 세트 1을 활용\n",
        "- 목표\n",
        "  - 교차 검증(cross validation)을 이용한 모델 트레이닝\n",
        "    - 검증 세트 예측단가와 검증 세트 실제 단가 차이 최소화\n",
        "    - 단가 차이는 평균 절대 오차(Mean Absolute Error: MAE)를 활용\n",
        "  - 트레이닝 된 모델에 테스트 세트1이 주어졌을 때 예측단가와 테스트 세트1의 실제 단가 차이로 측정되는 MAE를 최소화\n",
        "  - 다양한 모델을 트레이닝하여 MAE 최소화 모델 발견\n",
        "    - 회귀 (regression) 모델 필요\n",
        "    - 모델 후보: XGBRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
        "    - 모델 평가: cross validation\n",
        "    - 하이퍼 변수(hyper parameters) 최적화: gridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F90G33HXBpj"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dhz2j-EXwfi"
      },
      "source": [
        "### 데이터 전처리 (트레이닝 세트 & 테스트 세트1)\n",
        "  - 단가(P_PRICE)가 제공되지 않은 행(row) 제외\n",
        "  - 종속 변수(P_PRICE)와 독립변수(features) 분리\n",
        "  - 날짜(REG_DATE) 데이터 타입과 포맷 변경\n",
        "    - datetime64[ns] -> int\n",
        "    - 월/일/년 -> 년월일\n",
        "  - 상품 타입(P_TYPE)은 제거\n",
        "    - 해당 행 값은 항상 ‘수산물‘이므로 데이터 처리에 불필요\n",
        "  - 상품 수입 타입(P_IMPORT_TYPE)에 원 핫 엔코딩 적용\n",
        "    - 셀(cell)은 여러 값을 포함하고 있으므로 값들을 분리하고, 고유값을 레이벨(label)로 새로운데이터 프레임 생성. 고유값 포함은 0,1로 표기.\n",
        "    - 기존 데이터 프레임과 새로운 데이터 프레임을 합성 후 기존 상품 수입 타입은 삭제\n",
        "    - 트레이닝 세트와 테스트 세트에 따라 새로이 형성된 데이터 프레임 형태 통일\n",
        "  - 데이터 타입(dtype) 기반으로 열(columns) 분리\n",
        "    - 수치 열(dtype = int/float) – REG_DATE, P_IMPORT_TYPE 원 핫 엔코딩 결과물\n",
        "    - 카테고리 열(dtype = str) – CTRY_1, CTRY_2, … 등 수치 열을 제외한 모든 열\n",
        "  - 모든 열의 경우 SimpleImputer를 이용, 미싱값(missing values) 0으로 처리\n",
        "  - REG_DATE의 경우 표준화(StandardScaler) 적용\n",
        "  - 모든 카테고리 열의 경우 원 핫 엔코딩 적용\n",
        "    - 테스트동안 모르는 값 (unknown values) 발생 시 무시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOGvcoINXiOS"
      },
      "source": [
        "# 데이터의 경우 직접 업로드 필요 (구글 코랩 좌측 파일 박스(Files) 연 후 복사 붙이기)\n",
        "train_data = pd.read_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_문제데이터.xlsx')\n",
        "test_data = pd.read_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_자율평가데이터.xlsx')\n",
        "\n",
        "## P_PRICE 값이 없는 아이템(row) 제거\n",
        "if train_data.P_PRICE.isnull().any():\n",
        "    train_data.dropna(axis=0, subset=['P_PRICE'], inplace=True)\n",
        "elif test_data.P_PRICE.isnull().any():\n",
        "    test_data.dropna(axis=0, subset=['P_PRICE'], inplace=True)\n",
        "\n",
        "## 독립변수와 종속변수(P_PRICE) 분리\n",
        "y_train = train_data.P_PRICE \n",
        "X_train = train_data.drop(labels=['P_PRICE'], axis=1)\n",
        "\n",
        "y_test = test_data.P_PRICE\n",
        "X_test = test_data.drop(labels=['P_PRICE'], axis=1)\n",
        "\n",
        "## REG_DATE 데이터 타입(datetime64[ns]) 변경 -> int \n",
        "X_train.REG_DATE = X_train.REG_DATE.apply(lambda x: int(x.strftime('%y%m%d')))\n",
        "X_test.REG_DATE = X_test.REG_DATE.apply(lambda x: int(x.strftime('%y%m%d')))\n",
        "\n",
        "## P_TYPE 제거: 값이 항상 수산물이기 때문에 데이터 처리에 불필요\n",
        "X_train.drop(labels=['P_TYPE'], axis=1, inplace=True)\n",
        "X_test.drop(labels=['P_TYPE'], axis=1, inplace=True)\n",
        "\n",
        "## Manual One Hot Encoding 필요: P_IMPORT_TYPE 은 여러 요소의 값으로 이루어졌으므로 고유값 분리 후 적용\n",
        "## 기존 데이터 프레임과 새로운 데이터 프레임을 합친 후, 상품 수입 타입(P_IMPORT_TYPE)은 제거\n",
        "def converter(column):\n",
        "    '''주어진 Column에 쉼표(,)를 기준으로 셀(cell)값을 분리 후 고유값을 레이벨(Labels)로 하는 데이터프레임 생성. \n",
        "    고유값 포함은 0,1로 표기.'''\n",
        "    temp = column.copy()\n",
        "    temp = temp.str.split(',')\n",
        "    temp = temp.explode()\n",
        "    temp = pd.crosstab(temp.index, temp)\n",
        "    return temp\n",
        "\n",
        "X_train_P_IMPORT_TYPE = converter(X_train.P_IMPORT_TYPE)\n",
        "X_test_P_IMPORT_TYPE = converter(X_test.P_IMPORT_TYPE)\n",
        "X_train.drop(labels=['P_IMPORT_TYPE'], axis=1, inplace=True)\n",
        "X_test.drop(labels=['P_IMPORT_TYPE'], axis=1, inplace=True)\n",
        "X_train = X_train.join(X_train_P_IMPORT_TYPE)\n",
        "X_test = X_test.join(X_test_P_IMPORT_TYPE)\n",
        "\n",
        "## 트레이닝 세트와 테스트 세트에 따라 새로이 형성된 데이터 프레임 형태 통일\n",
        "feature_diff = set(X_train_P_IMPORT_TYPE) - set(X_test_P_IMPORT_TYPE)\n",
        "feature_diff_df = pd.DataFrame(data=np.zeros((X_test_P_IMPORT_TYPE.shape[0], len(feature_diff))),\n",
        "                               columns=list(feature_diff), dtype=int)\n",
        "\n",
        "X_test = X_test.join(feature_diff_df)\n",
        "X_test = X_test[list(X_train.columns)]\n",
        "\n",
        "## 열(columns) 분리 (데이터 타입(dtype) 기반) 후 해당 트랜스포머 파이프라인에 저장\n",
        "numerical_cols = ['REG_DATE']\n",
        "numerical_cols_oh = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\n",
        "numerical_cols_oh.remove('REG_DATE')\n",
        "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n",
        "                                        ('scale', StandardScaler())])\n",
        "\n",
        "numerical_transformer_oh = SimpleImputer(strategy='constant')\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n",
        "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
        "                                               ('num_oh', numerical_transformer_oh, numerical_cols_oh),\n",
        "                                               ('cat', categorical_transformer, categorical_cols)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDoClgmBY0s4"
      },
      "source": [
        "### 모델 적용 및 해달 모델 하이퍼 변수(hyper-parameters) 최적화\n",
        "  - XGBRegression 모델의 경우, 트레이닝 세트를 이용한 교차검증(Cross-validation)과 테스트 세트 예측에서 가장 낮은 평균 절대 오차를 보입니다.\n",
        "  - XGBRegression의 경우 Gradient Boosting을 활용하는 알고리즘이며, 이는\n",
        "판단 트리 (Decision tree)와 같은 위크 러너(weak learner)의 단점을 보완합니다. 따라서 사용된 다른 알고리듬에 비해서 상대적으로 뛰어난 결과를 보여주는걸로 예상됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgSFqgfKYa2A",
        "outputId": "80e4382f-0f76-47db-d9e0-fdf63b609e44"
      },
      "source": [
        "models = [XGBRegressor(random_state=0), LinearRegression(), Ridge(random_state=0), Lasso(random_state=0), ElasticNet(random_state=0)]\n",
        "params = [{'clf__n_estimators': [800, 1000],'clf__max_depth': [6,8], 'clf__learning_rate': [0.1]},\n",
        "          {},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0], 'clf__l1_ratio': [0.5, 0.8]}]\n",
        "for mod, par in zip(models, params):\n",
        "    X_valid, y_valid = X_train.copy(), y_train.copy()\n",
        "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                  ('clf', mod)])\n",
        "    clf = GridSearchCV(estimator = my_pipeline,\n",
        "                        param_grid = par,\n",
        "                        scoring='neg_mean_absolute_error',\n",
        "                        cv=5)\n",
        "    clf.fit(X_valid, y_valid)\n",
        "    pred = clf.best_estimator_.predict(X_test)\n",
        "    print(f'\\nEstimator: {mod} \\nHyperparams: {clf.best_params_}, MAE(training): {-1 * clf.best_score_:.3f}, MAE(test): {mean_absolute_error(pred, y_test):.3f}\\n')\n",
        "    print('Product  \\t\\t\\tPredict\\t\\t\\tReal')\n",
        "    for i in range(10):\n",
        "        print(\"{:7}\\t\\t\\t{:.2f}\\t\\t\\t{:.2f}\".format(X_test.P_NAME.iloc[i], pred[i], y_test[i]))\n",
        "    print('\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:54:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:55:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:55:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:55:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:55:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:56:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:56:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:56:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:56:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:57:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:57:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:57:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:58:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:58:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:58:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:58:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:59:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:59:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:00:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:00:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:00:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "Estimator: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1) \n",
            "Hyperparams: {'clf__learning_rate': 0.1, 'clf__max_depth': 8, 'clf__n_estimators': 1000}, MAE(training): 1.686, MAE(test): 1.952\n",
            "\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "남방참다랑어 \t\t\t12.16\t\t\t4.88\n",
            "은연어    \t\t\t6.28\t\t\t5.39\n",
            "강도다리   \t\t\t7.02\t\t\t6.76\n",
            "자주복    \t\t\t18.00\t\t\t18.50\n",
            "은밀복    \t\t\t3.09\t\t\t3.07\n",
            "바리,교잡종 \t\t\t12.69\t\t\t14.00\n",
            "까칠복    \t\t\t2.23\t\t\t1.73\n",
            "젓새우    \t\t\t1.15\t\t\t1.40\n",
            "적새우    \t\t\t6.24\t\t\t5.67\n",
            "바지락    \t\t\t3.19\t\t\t2.69\n",
            "\n",
            "\n",
            "\n",
            "Estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
            "Hyperparams: {}, MAE(training): 4.269, MAE(test): 4.388\n",
            "\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "남방참다랑어 \t\t\t9.48\t\t\t4.88\n",
            "은연어    \t\t\t46.17\t\t\t5.39\n",
            "강도다리   \t\t\t7.34\t\t\t6.76\n",
            "자주복    \t\t\t18.29\t\t\t18.50\n",
            "은밀복    \t\t\t3.56\t\t\t3.07\n",
            "바리,교잡종 \t\t\t12.30\t\t\t14.00\n",
            "까칠복    \t\t\t2.27\t\t\t1.73\n",
            "젓새우    \t\t\t0.61\t\t\t1.40\n",
            "적새우    \t\t\t6.95\t\t\t5.67\n",
            "바지락    \t\t\t-0.77\t\t\t2.69\n",
            "\n",
            "\n",
            "\n",
            "Estimator: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "      normalize=False, random_state=0, solver='auto', tol=0.001) \n",
            "Hyperparams: {'clf__alpha': 1.0}, MAE(training): 4.263, MAE(test): 4.406\n",
            "\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "남방참다랑어 \t\t\t10.56\t\t\t4.88\n",
            "은연어    \t\t\t43.46\t\t\t5.39\n",
            "강도다리   \t\t\t7.20\t\t\t6.76\n",
            "자주복    \t\t\t18.24\t\t\t18.50\n",
            "은밀복    \t\t\t3.56\t\t\t3.07\n",
            "바리,교잡종 \t\t\t12.38\t\t\t14.00\n",
            "까칠복    \t\t\t2.34\t\t\t1.73\n",
            "젓새우    \t\t\t0.67\t\t\t1.40\n",
            "적새우    \t\t\t6.88\t\t\t5.67\n",
            "바지락    \t\t\t-0.86\t\t\t2.69\n",
            "\n",
            "\n",
            "\n",
            "Estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
            "      normalize=False, positive=False, precompute=False, random_state=0,\n",
            "      selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1}, MAE(training): 5.039, MAE(test): 5.529\n",
            "\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "남방참다랑어 \t\t\t18.24\t\t\t4.88\n",
            "은연어    \t\t\t18.83\t\t\t5.39\n",
            "강도다리   \t\t\t7.83\t\t\t6.76\n",
            "자주복    \t\t\t7.83\t\t\t18.50\n",
            "은밀복    \t\t\t1.17\t\t\t3.07\n",
            "바리,교잡종 \t\t\t7.83\t\t\t14.00\n",
            "까칠복    \t\t\t1.17\t\t\t1.73\n",
            "젓새우    \t\t\t8.09\t\t\t1.40\n",
            "적새우    \t\t\t4.47\t\t\t5.67\n",
            "바지락    \t\t\t0.47\t\t\t2.69\n",
            "\n",
            "\n",
            "\n",
            "Estimator: ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
            "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1, 'clf__l1_ratio': 0.8}, MAE(training): 5.550, MAE(test): 6.448\n",
            "\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "남방참다랑어 \t\t\t11.46\t\t\t4.88\n",
            "은연어    \t\t\t10.28\t\t\t5.39\n",
            "강도다리   \t\t\t7.73\t\t\t6.76\n",
            "자주복    \t\t\t7.73\t\t\t18.50\n",
            "은밀복    \t\t\t1.35\t\t\t3.07\n",
            "바리,교잡종 \t\t\t7.73\t\t\t14.00\n",
            "까칠복    \t\t\t1.35\t\t\t1.73\n",
            "젓새우    \t\t\t8.87\t\t\t1.40\n",
            "적새우    \t\t\t4.39\t\t\t5.67\n",
            "바지락    \t\t\t2.45\t\t\t2.69\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4uLxa11ZzGr"
      },
      "source": [
        "### 최적화 XGBRegression 및 주요 오류 상품 조사\n",
        "  - 테스트 세트 평균 절대 오차를 조사하였을 때 특정 아이템의 편차가 큼을 발견\n",
        "    - 테스트 MAE > 20 시행: 123 아이템 발견(성게알 85, 해삼 15)\n",
        "    - 성게알 제외 후 -> 트레이닝 MAE : 1.43, 테스트 MAE : 1.312\n",
        "    - 성게알과 해삼 제외 후 -> 트레이닝 MAE : 1.310, 테스트 MAE : 1.25\n",
        "  - 성게알, 해삼 관련 데이터가 보완 될 경우 더 좋은 모델로 성장할 것으로 예상    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpW5-ouXZstQ",
        "outputId": "80c25108-1b36-4607-c9f6-2b74425b5e4b"
      },
      "source": [
        "new_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('xgb', XGBRegressor(random_state=0))])\n",
        "xgb = GridSearchCV(estimator = new_pipeline,\n",
        "                    param_grid = {'xgb__n_estimators': [1000],\n",
        "                                  'xgb__max_depth': [8], \n",
        "                                  'xgb__learning_rate': [0.1]},\n",
        "                    scoring='neg_mean_absolute_error',\n",
        "                    n_jobs=-1,\n",
        "                    cv=5)\n",
        "xgb.fit(X_train, y_train)\n",
        "pred = xgb.best_estimator_.predict(X_test)\n",
        "count = 0\n",
        "print('주 오류 상품 조사')\n",
        "print('Product  \\t\\t\\tPredict\\t\\t\\tReal')\n",
        "for i in range(y_test.shape[0]):\n",
        "    if abs(pred[i] - y_test[i]) > 20.0:\n",
        "        print(\"{:7}\\t\\t\\t{:.2f}\\t\\t\\t{:.2f}\".format(X_test.P_NAME.iloc[i], pred[i], y_test[i]))\n",
        "        count = count + 1\n",
        "print(f'{count}항목에서 MAE>20.0 발견')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:03:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "주 오류 상품 조사\n",
            "Product  \t\t\tPredict\t\t\tReal\n",
            "성게알    \t\t\t336.91\t\t\t362.06\n",
            "성게알    \t\t\t18.96\t\t\t80.00\n",
            "성게알    \t\t\t93.32\t\t\t194.50\n",
            "성게알    \t\t\t336.91\t\t\t316.15\n",
            "성게알    \t\t\t93.32\t\t\t120.63\n",
            "해삼     \t\t\t92.26\t\t\t53.00\n",
            "성게알    \t\t\t336.91\t\t\t220.96\n",
            "성게알    \t\t\t336.91\t\t\t242.61\n",
            "성게알    \t\t\t69.26\t\t\t44.87\n",
            "성게알    \t\t\t336.91\t\t\t262.52\n",
            "해삼     \t\t\t84.62\t\t\t106.56\n",
            "성게알    \t\t\t336.91\t\t\t260.56\n",
            "성게알    \t\t\t336.91\t\t\t255.46\n",
            "낙지     \t\t\t11.17\t\t\t36.42\n",
            "성게알    \t\t\t336.91\t\t\t205.14\n",
            "왕게     \t\t\t36.99\t\t\t63.50\n",
            "낙지     \t\t\t11.17\t\t\t36.42\n",
            "해삼     \t\t\t92.26\t\t\t62.41\n",
            "청새리상어  \t\t\t156.82\t\t\t229.57\n",
            "해삼     \t\t\t191.52\t\t\t63.50\n",
            "흰다리새우  \t\t\t11.65\t\t\t34.16\n",
            "성게알    \t\t\t336.91\t\t\t233.95\n",
            "성게알    \t\t\t336.91\t\t\t307.84\n",
            "낙지     \t\t\t11.17\t\t\t31.22\n",
            "성게알    \t\t\t93.32\t\t\t128.36\n",
            "성게알    \t\t\t336.91\t\t\t269.58\n",
            "해삼     \t\t\t240.42\t\t\t265.00\n",
            "성게알    \t\t\t336.91\t\t\t242.49\n",
            "성게알    \t\t\t93.32\t\t\t141.74\n",
            "성게알    \t\t\t336.91\t\t\t236.17\n",
            "성게알    \t\t\t336.91\t\t\t194.45\n",
            "성게알    \t\t\t336.91\t\t\t193.62\n",
            "성게알    \t\t\t336.91\t\t\t207.63\n",
            "성게알    \t\t\t336.91\t\t\t180.31\n",
            "성게알    \t\t\t93.32\t\t\t130.52\n",
            "성게알    \t\t\t87.59\t\t\t115.20\n",
            "성게알    \t\t\t336.91\t\t\t178.19\n",
            "성게알    \t\t\t87.59\t\t\t121.94\n",
            "성게알    \t\t\t93.32\t\t\t130.52\n",
            "성게알    \t\t\t336.91\t\t\t184.57\n",
            "성게알    \t\t\t87.59\t\t\t121.33\n",
            "성게알    \t\t\t93.32\t\t\t130.52\n",
            "성게알    \t\t\t336.91\t\t\t209.19\n",
            "해삼     \t\t\t92.26\t\t\t17.74\n",
            "성게알    \t\t\t93.32\t\t\t130.18\n",
            "성게알    \t\t\t87.59\t\t\t120.26\n",
            "성게알    \t\t\t336.91\t\t\t170.48\n",
            "청새리상어  \t\t\t156.82\t\t\t217.18\n",
            "성게알    \t\t\t87.59\t\t\t118.00\n",
            "가시투성왕게 \t\t\t39.84\t\t\t19.06\n",
            "성게알    \t\t\t336.91\t\t\t219.07\n",
            "해삼     \t\t\t84.62\t\t\t107.56\n",
            "가시투성왕게 \t\t\t39.84\t\t\t16.00\n",
            "성게알    \t\t\t87.59\t\t\t118.29\n",
            "성게알    \t\t\t336.91\t\t\t224.41\n",
            "남방참다랑어 \t\t\t12.16\t\t\t118.74\n",
            "성게알    \t\t\t87.59\t\t\t117.24\n",
            "성게알    \t\t\t336.91\t\t\t227.12\n",
            "해삼     \t\t\t191.52\t\t\t63.03\n",
            "가리비    \t\t\t25.26\t\t\t46.67\n",
            "성게알    \t\t\t87.59\t\t\t117.79\n",
            "가시투성왕게 \t\t\t39.84\t\t\t13.50\n",
            "성게알    \t\t\t336.91\t\t\t231.14\n",
            "해삼     \t\t\t92.26\t\t\t65.09\n",
            "성게알    \t\t\t87.59\t\t\t117.77\n",
            "성게알    \t\t\t336.91\t\t\t253.10\n",
            "왕게붙이   \t\t\t14.76\t\t\t40.00\n",
            "성게알    \t\t\t87.59\t\t\t118.00\n",
            "성게알    \t\t\t336.91\t\t\t259.14\n",
            "해삼     \t\t\t92.26\t\t\t53.86\n",
            "성게알    \t\t\t79.92\t\t\t115.55\n",
            "해삼     \t\t\t240.42\t\t\t261.26\n",
            "성게알    \t\t\t87.59\t\t\t117.76\n",
            "성게알    \t\t\t336.91\t\t\t275.03\n",
            "명태     \t\t\t3.32\t\t\t36.40\n",
            "성게알    \t\t\t87.59\t\t\t119.36\n",
            "성게알    \t\t\t79.92\t\t\t106.78\n",
            "성게알    \t\t\t336.91\t\t\t265.83\n",
            "눈다랑어   \t\t\t13.90\t\t\t58.61\n",
            "성게알    \t\t\t336.91\t\t\t292.89\n",
            "성게알    \t\t\t87.59\t\t\t128.69\n",
            "성게알    \t\t\t336.91\t\t\t386.69\n",
            "성게알    \t\t\t87.59\t\t\t124.92\n",
            "해삼     \t\t\t84.62\t\t\t111.60\n",
            "성게알    \t\t\t336.91\t\t\t383.53\n",
            "성게알    \t\t\t87.59\t\t\t119.11\n",
            "성게알    \t\t\t93.32\t\t\t120.22\n",
            "성게알    \t\t\t336.91\t\t\t380.35\n",
            "성게알    \t\t\t336.91\t\t\t279.17\n",
            "성게알    \t\t\t87.59\t\t\t120.72\n",
            "성게알    \t\t\t336.91\t\t\t433.06\n",
            "성게알    \t\t\t93.32\t\t\t197.72\n",
            "성게알    \t\t\t336.91\t\t\t629.36\n",
            "참다랑어   \t\t\t36.87\t\t\t7.84\n",
            "성게알    \t\t\t336.91\t\t\t399.16\n",
            "참다랑어   \t\t\t39.02\t\t\t7.24\n",
            "성게알    \t\t\t93.32\t\t\t164.30\n",
            "왕게     \t\t\t36.99\t\t\t76.36\n",
            "성게알    \t\t\t336.91\t\t\t376.34\n",
            "성게알    \t\t\t93.32\t\t\t148.08\n",
            "성게알    \t\t\t336.91\t\t\t381.60\n",
            "연어     \t\t\t16.46\t\t\t46.63\n",
            "성게알    \t\t\t93.32\t\t\t151.64\n",
            "성게알    \t\t\t336.91\t\t\t426.33\n",
            "참다랑어   \t\t\t8.50\t\t\t41.64\n",
            "해삼     \t\t\t92.26\t\t\t67.44\n",
            "성게알    \t\t\t93.32\t\t\t148.90\n",
            "성게알    \t\t\t336.91\t\t\t379.77\n",
            "참다랑어   \t\t\t40.70\t\t\t17.01\n",
            "성게알    \t\t\t93.32\t\t\t163.11\n",
            "성게알    \t\t\t336.91\t\t\t378.01\n",
            "성게알    \t\t\t93.32\t\t\t144.67\n",
            "성게알    \t\t\t93.32\t\t\t156.23\n",
            "참다랑어   \t\t\t9.57\t\t\t31.85\n",
            "성게알    \t\t\t93.32\t\t\t165.71\n",
            "명태     \t\t\t3.32\t\t\t28.63\n",
            "성게알    \t\t\t93.32\t\t\t142.05\n",
            "해삼     \t\t\t98.17\t\t\t130.25\n",
            "성게알    \t\t\t93.32\t\t\t144.29\n",
            "성게알    \t\t\t336.91\t\t\t384.77\n",
            "해삼     \t\t\t84.62\t\t\t114.17\n",
            "성게알    \t\t\t93.32\t\t\t143.38\n",
            "성게알    \t\t\t336.91\t\t\t432.02\n",
            "123항목에서 MAE>20.0 발견\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxtRDLYNaDlQ"
      },
      "source": [
        "### 주요 오류 상품인 성개알 제거 후 트레이닝 & 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIGje1vZ_jT",
        "outputId": "b448a340-ad9b-466e-f23b-5e9105ba651d"
      },
      "source": [
        "## 성개알 제거 후 트레이닝 및 테스트 \n",
        "inx = []\n",
        "for i in range(X_train.shape[0]):\n",
        "    if X_train.P_NAME.iloc[i] == '성게알':\n",
        "        inx.append(i)\n",
        "X_train_s = X_train.drop(index = inx)\n",
        "y_train_s = y_train.drop(index = inx)\n",
        "X_train_s.reset_index(drop=True, inplace=True)\n",
        "y_train_s.reset_index(drop=True, inplace=True)\n",
        "\n",
        "inx = []\n",
        "for i in range(y_test.shape[0]):\n",
        "    if X_test.P_NAME.iloc[i] == '성게알':\n",
        "        inx.append(i)\n",
        "X_test_s = X_test.drop(index = inx)\n",
        "y_test_s = y_test.drop(index = inx)\n",
        "X_test_s.reset_index(drop=True, inplace=True)\n",
        "y_test_s.reset_index(drop=True, inplace=True)\n",
        "\n",
        "xgb.fit(X_train_s, y_train_s)\n",
        "pred = xgb.best_estimator_.predict(X_test_s)\n",
        "print(f'\\n성게알 제거 후 MAE(training): {-1 * xgb.best_score_:.3f}, MAE(test): {mean_absolute_error(pred, y_test_s):.3f}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:07:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "성게알 제거 후 MAE(training): 1.430, MAE(test): 1.312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGUoRn3AaQSR"
      },
      "source": [
        "### 주요 오류 상품인 성개알과 해삼 제거 후 트레이닝 & 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShwLlSc3aOAm",
        "outputId": "07289ae7-762c-43b5-cda3-d25b046e5455"
      },
      "source": [
        "## 성게알과 해삼 제거 후 트레이밍 및 테스트\n",
        "inx = []\n",
        "for i in range(X_train.shape[0]):\n",
        "    if X_train.P_NAME.iloc[i] == '성게알' or X_train.P_NAME.iloc[i] == '해삼':\n",
        "        inx.append(i)\n",
        "X_train_sh = X_train.drop(index = inx)\n",
        "y_train_sh = y_train.drop(index = inx)\n",
        "X_train_sh.reset_index(drop=True, inplace=True)\n",
        "y_train_sh.reset_index(drop=True, inplace=True)\n",
        "\n",
        "inx = []\n",
        "for i in range(y_test.shape[0]):\n",
        "    if X_test.P_NAME.iloc[i] == '성게알' or X_test.P_NAME.iloc[i] == '해삼':\n",
        "        inx.append(i)\n",
        "X_test_sh = X_test.drop(index = inx)\n",
        "y_test_sh = y_test.drop(index = inx)\n",
        "X_test_sh.reset_index(drop=True, inplace=True)\n",
        "y_test_sh.reset_index(drop=True, inplace=True)\n",
        "\n",
        "xgb.fit(X_train_sh, y_train_sh)\n",
        "pred = xgb.best_estimator_.predict(X_test_sh)\n",
        "print(f'\\n성게알과 해삼 제거 후 MAE(training): {-1 * xgb.best_score_:.3f}, MAE(test): {mean_absolute_error(pred, y_test_sh):.3f}\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:10:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "성게알과 해삼 제거 후 MAE(training): 1.310, MAE(test): 1.250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4MQcV4dI8V"
      },
      "source": [
        "## 테스트 세트2 예측 모델 수립\n",
        "  - 데이터: 트레이닝 세트와 테스트 세트 1&2를 활용\n",
        "  - 목표\n",
        "    - 새로운 트레이닝 데이터 생성: 기존 트레이닝 세트 + 테스트 세트1\n",
        "    - 교차 검증(cross validation)을 이용한 모델 트레이닝\n",
        "      - 검증 세트 예측단가와 검증 세트 실제 단가 차이 최소화\n",
        "      - 값의 차이는 평균 절대 오차(Mean Absolute Error)를 이용\n",
        "    - 트레이닝 된 모델에 테스트 세트2가 주어졌을 때 단가 예측\n",
        "    - 다양한 모델을 트레이닝하여 교차 검증 MAE 최소화 모델 발견\n",
        "      - 회귀 (regression) 모델 필요\n",
        "      - 모델 후보: XGBRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
        "      - 모델 평가: cross validation\n",
        "      - 하이퍼 변수(hyper parameters) 최적화: gridsearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x42QnnTGkSot"
      },
      "source": [
        "### 데이터 전처리(테스트 세트2)\n",
        "  - 테스트 세트2\n",
        "    - 불필요한 인덱스 제거 (행[0])\n",
        "    - NaN 처리: 어종(CATEGORY_2), 상세어종(P_NAME)\n",
        "    - 어종(CATEGORY_2), 상세어종(P_NAME), 일자(REG_DATE), 예측단가(P_PRICE) 레이벨링\n",
        "    - 종속 변수(P_PRICE)와 독립변수(features) 분리\n",
        "    - 날짜(REG_DATE) 데이터 타입과 포맷 변경\n",
        "      - datetime64[ns] -> int\n",
        "      - 월/일/년 -> 년월일\n",
        "  - 기존 트레이닝 세트와 테스트 세트1의 선택된 특정 독립 변수(어종, 상세어종, 일자)와 종속 변수(단가)에 해당하는 데이터만을 추출 후 새로운 트레이닝 세트 생성\n",
        "  - 신규 트레이닝 세트 + 테스트 세트2\n",
        "    - 데이터 타입(dtype) 기반으로 열(columns) 분리\n",
        "      - 수치 열(dtype = int/float) – REG_DATE\n",
        "      - 카테고리 열(dtype = str) – CATEGORY_2, P_NAME\n",
        "    - 모든 열의 경우 SimpleImputer를 이용, 미싱값(missing values) 처리\n",
        "    - REG_DATE의 경우 표준화(StandardScaler) 적용\n",
        "    - 모든 카테고리 열의 경우 원 핫 엔코딩 적용\n",
        "      - 테스트동안 모르는 값 (unknown values) 발생 시 무시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lsOjMScdD26"
      },
      "source": [
        "## 테스트 세트2 불러오기\n",
        "test_data2 = pd.read_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_평가데이터_update_210831.xlsx', \n",
        "                            header=None)\n",
        "\n",
        "## 불필요한 인덱스 제거\n",
        "test_data2.drop(index=0, inplace=True)\n",
        "test_data2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "## NaN 채워넣기: 어종(CATEGORY_2), 상세어종(P_NAME)\n",
        "missing_index = [0,1,5,6,10,11]\n",
        "for i in missing_index:\n",
        "    test_data2.iloc[:,i].fillna(test_data2.iloc[0,i], inplace=True)\n",
        "\n",
        "\n",
        "## 데이터 처리 효율 향상을 위해 어종(CATEGORY_2), 상세어종(P_NAME), 일자(REG_DATE), \n",
        "## 예측 단가(P_PRICE)에 따라 데이터프레임 3 등분\n",
        "columns = ['CATEGORY_2','P_NAME','REG_DATE','P_PRICE']\n",
        "test_data2_1 = test_data2.iloc[:,:4]\n",
        "test_data2_1.columns = columns\n",
        "test_data2_2 = test_data2.iloc[:,5:9]\n",
        "test_data2_2.columns = columns\n",
        "test_data2_3 = test_data2.iloc[:,10:14]\n",
        "test_data2_3.columns = columns\n",
        "\n",
        "\n",
        "## 독립변수와 종속변수(P_PRICE) 분리\n",
        "X_test2_1 = test_data2_1.drop(labels='P_PRICE', axis=1)\n",
        "X_test2_2 = test_data2_2.drop(labels='P_PRICE', axis=1)\n",
        "X_test2_3 = test_data2_3.drop(labels='P_PRICE', axis=1)\n",
        "\n",
        "\n",
        "## REG_DATE 데이터 타입(datetime64[ns]) 변경 -> int \n",
        "X_test2_1.REG_DATE = X_test2_1.REG_DATE.apply(lambda x: int(x.strftime('%y%m%d')))\n",
        "X_test2_2.REG_DATE = X_test2_2.REG_DATE.apply(lambda x: int(x.strftime('%y%m%d')))\n",
        "X_test2_3.REG_DATE = X_test2_3.REG_DATE.apply(lambda x: int(x.strftime('%y%m%d')))\n",
        "\n",
        "\n",
        "## 트레이닝 세트와 테스트 세트1의 특정 독립 변수(어종, 상세어종, 날짜, 가격)와 \n",
        "## 종속 변수(가격)에 해당하는 데이터를 추출 후 새로운 트레이닝 세트 작성\n",
        "y_train2 = y_train.copy()\n",
        "X_train2 = X_train.loc[:,['CATEGORY_2','P_NAME','REG_DATE']].copy()\n",
        "y_test2 = y_test.copy()\n",
        "X_test2 = X_test.loc[:,['CATEGORY_2','P_NAME','REG_DATE']].copy()\n",
        "\n",
        "y_train2 = y_train2.append(y_test2, ignore_index=True)\n",
        "X_train2 = X_train2.append(X_test2, ignore_index=True)\n",
        "\n",
        "\n",
        "## 열(columns) 분리 (데이터 타입(dtype) 기반) 후 해당 트랜스포머 파이프라인에 저장\n",
        "numeric_cols = ['REG_DATE']\n",
        "categoric_cols = ['CATEGORY_2','P_NAME']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n",
        "                                      ('scale', StandardScaler())])\n",
        "\n",
        "categoric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n",
        "                                        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocess = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_cols),\n",
        "                                             ('cat', categoric_transformer, categoric_cols)])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzlnSZrAfHnp"
      },
      "source": [
        "### 모델 적용 및 해달 모델 하이퍼 변수(hyper-parameters) 최적화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A578zyRfIoY",
        "outputId": "9ec734a7-ad1a-4010-e136-d5438dac7817"
      },
      "source": [
        "models = [XGBRegressor(random_state=0), LinearRegression(), Ridge(random_state=0), Lasso(random_state=0), ElasticNet(random_state=0)]\n",
        "params = [{'clf__n_estimators': [800, 1000],'clf__max_depth': [6,8], 'clf__learning_rate': [0.1, 0.5]},\n",
        "          {},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0], 'clf__l1_ratio': [0.5, 0.8]}]\n",
        "for mod, par in zip(models, params):\n",
        "    X_valid, y_valid = X_train2.copy(), y_train2.copy()\n",
        "    my_pipeline = Pipeline(steps=[('preprocessor', preprocess),\n",
        "                                  ('clf', mod)])\n",
        "    clf = GridSearchCV(estimator = my_pipeline,\n",
        "                        param_grid = par,\n",
        "                        scoring='neg_mean_absolute_error',\n",
        "                        n_jobs=-1,\n",
        "                        cv=5)\n",
        "    clf.fit(X_valid, y_valid)\n",
        "    print(f'\\nEstimator: {mod} \\nHyperparams: {clf.best_params_}, MAE(training): {-1 * clf.best_score_:.3f}\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:19:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "Estimator: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1) \n",
            "Hyperparams: {'clf__learning_rate': 0.1, 'clf__max_depth': 6, 'clf__n_estimators': 1000}, MAE(training): 3.680\n",
            "\n",
            "\n",
            "Estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
            "Hyperparams: {}, MAE(training): 3.822\n",
            "\n",
            "\n",
            "Estimator: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "      normalize=False, random_state=0, solver='auto', tol=0.001) \n",
            "Hyperparams: {'clf__alpha': 0.1}, MAE(training): 3.823\n",
            "\n",
            "\n",
            "Estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
            "      normalize=False, positive=False, precompute=False, random_state=0,\n",
            "      selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1}, MAE(training): 5.530\n",
            "\n",
            "\n",
            "Estimator: ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
            "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1, 'clf__l1_ratio': 0.8}, MAE(training): 6.319\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftHvJ9CNfRe1"
      },
      "source": [
        "### 최적화 XGBRegression과 LinearRegression 사용 및 데이터 출력\n",
        "- XGBRegression의 경우 Gradient Boosting 알고리듬을 활용하기에 큰틀을 잡고 측정하는데는 뛰어난 장점이 있지만, 그 장점 때문에 아주 미세한 차이를 놓치게 되어 LinearRegression 보다 뒤쳐지는 것으로 보입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rThCt8uQfR1g",
        "outputId": "e3d07e7f-69ec-42e6-9396-e5a33a018042"
      },
      "source": [
        "# XGBRegression\n",
        "new_pipeline = Pipeline(steps=[('preprocessor', preprocess),\n",
        "                              ('xgb', XGBRegressor(random_state=0))])\n",
        "xgb = GridSearchCV(estimator = new_pipeline,\n",
        "                   param_grid = {'xgb__n_estimators': [1000],\n",
        "                                 'xgb__max_depth': [6], \n",
        "                                 'xgb__learning_rate': [0.1]},\n",
        "                   scoring='neg_mean_absolute_error',\n",
        "                   n_jobs=-1,\n",
        "                   cv=5)\n",
        "X_valid, y_valid = X_train2.copy(), y_train2.copy()\n",
        "xgb.fit(X_valid, y_valid)\n",
        "print('XGBRegressor')\n",
        "for s in [X_test2_1, X_test2_2, X_test2_3]:\n",
        "    name = s.P_NAME.iloc[0]\n",
        "    pred = xgb.best_estimator_.predict(s)\n",
        "    print(f'{name}\\n{pred}')\n",
        "    \n",
        "X_test2_cum = (X_test2_1.append(X_test2_2, ignore_index=True)).append(X_test2_3, ignore_index=True)    \n",
        "pred = xgb.predict(X_test2_cum)\n",
        "X_test2_cum['P_PRICE'] = pred\n",
        "X_test2_cum.REG_DATE = pd.to_datetime(X_test2_cum.REG_DATE, format='%y%m%d').dt.date\n",
        "X_test2_cum.columns = ['품목', '상세품목', '날짜', '예측단가']\n",
        "X_test2_cum.to_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_평가데이터_update_210831_예측(xgb).xlsx',\n",
        "                     index=False)\n",
        "\n",
        "# LinearRegression\n",
        "new_pipeline = Pipeline(steps=[('preprocessor', preprocess),\n",
        "                              ('lR', LinearRegression())])\n",
        "linR = GridSearchCV(estimator = new_pipeline,\n",
        "                    param_grid = {},\n",
        "                    scoring='neg_mean_absolute_error',\n",
        "                    n_jobs=-1,\n",
        "                    cv=5)\n",
        "X_valid, y_valid = X_train2.copy(), y_train2.copy()\n",
        "linR.fit(X_valid, y_valid)\n",
        "print('\\nLinearRegression')\n",
        "for s in [X_test2_1, X_test2_2, X_test2_3]:\n",
        "    name = s.P_NAME.iloc[0]\n",
        "    pred = linR.best_estimator_.predict(s)\n",
        "    print(f'{name}\\n{pred}')\n",
        "    \n",
        "X_test2_cum = (X_test2_1.append(X_test2_2, ignore_index=True)).append(X_test2_3, ignore_index=True)    \n",
        "pred = linR.predict(X_test2_cum)\n",
        "X_test2_cum['P_PRICE'] = pred\n",
        "X_test2_cum.REG_DATE = pd.to_datetime(X_test2_cum.REG_DATE, format='%y%m%d').dt.date\n",
        "X_test2_cum.columns = ['품목', '상세품목', '날짜', '예측단가']\n",
        "X_test2_cum.to_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_평가데이터_update_210831_예측(LR).xlsx',\n",
        "                     index=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:36:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBRegressor\n",
            "오징어\n",
            "[2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774\n",
            " 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774\n",
            " 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774\n",
            " 2.8268774 2.8268774 2.8268774 2.8268774 2.8268774]\n",
            "연어\n",
            "[13.332984 13.332984 13.332984 13.332984 13.332984 13.332984 13.332984\n",
            " 13.332984 13.332984 13.332984 13.332984 13.332984 13.332984 13.332984\n",
            " 13.332984 13.332984 13.332984 13.332984 13.332984 13.332984 13.332984\n",
            " 13.332984 13.332984 13.332984 13.332984 13.332984]\n",
            "흰다리새우\n",
            "[10.0239525 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525\n",
            " 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525\n",
            " 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525\n",
            " 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525 10.0239525\n",
            " 10.0239525 10.0239525]\n",
            "\n",
            "LinearRegression\n",
            "오징어\n",
            "[3.61206022 3.61226162 3.61246303 3.61266444 3.61485114 3.61505255\n",
            " 3.61525396 3.61545536 3.61772838 3.61792979 3.6181312  3.6183326\n",
            " 3.61853401 3.62072071 3.62092212 3.62112353 3.62132493 3.62354041\n",
            " 3.62374182 3.62394322 3.62414463 3.62434604 3.62653274 3.62673415\n",
            " 3.62693555 3.62713696]\n",
            "연어\n",
            "[15.39633308 15.39653448 15.39673589 15.3969373  15.399124   15.39932541\n",
            " 15.39952681 15.39972822 15.40200124 15.40220265 15.40240405 15.40260546\n",
            " 15.40280687 15.40499357 15.40519498 15.40539638 15.40559779 15.40781327\n",
            " 15.40801467 15.40821608 15.40841749 15.40861889 15.4108056  15.411007\n",
            " 15.41120841 15.41140982]\n",
            "흰다리새우\n",
            "[10.97981401 10.98001542 10.98021682 10.98041823 10.98260493 10.98280634\n",
            " 10.98300775 10.98320915 10.98548218 10.98568358 10.98588499 10.9860864\n",
            " 10.9862878  10.98847451 10.98867591 10.98887732 10.98907873 10.9912942\n",
            " 10.99149561 10.99169702 10.99189842 10.99209983 10.99428653 10.99448794\n",
            " 10.99468935 10.99489075]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja1jLzkgfoQx"
      },
      "source": [
        "## 트레이닝 데이터를 테스트 데이터에 편향하여 조작한 경우\n",
        "  - 트레이닝 세트에서 오징어, 연어, 흰다리 새우를 제외한 나머지 데이터들을 제거 하고 트레이닝 할 경우, 일자의 비중이 올라가기 때문에 테스트 결과가 훨씬 정밀하게 나타날 수 있습니다. 하지만 테스트 세트의 데이터를 미리 보고 거기에 맞추어 모델 트레이닝을 하는건 실제론 불가능하지만 차이 비교를 위해 진행했습니다.\n",
        "  - 오징어, 연어, 흰다리 새우를 제외한 모든행 제거후 트레이닝 및 테스트 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMJAccwufzJ6",
        "outputId": "65e19ee6-6ece-4963-a2f3-36287c90dabc"
      },
      "source": [
        "inx = []\n",
        "for i in range(X_train2.shape[0]):\n",
        "    if X_train2.P_NAME.iloc[i] == '오징어' or X_train2.P_NAME.iloc[i] == '연어' or X_train2.P_NAME.iloc[i] == '흰다리새우':\n",
        "        inx.append(i)\n",
        "X_train2_chosen = X_train2.iloc[inx]\n",
        "y_train2_chosen = y_train2.iloc[inx]\n",
        "X_train2_chosen.reset_index(drop=True, inplace=True)\n",
        "y_train2_chosen.reset_index(drop=True, inplace=True)\n",
        "\n",
        "models = [XGBRegressor(random_state=0), LinearRegression(), Ridge(random_state=0), Lasso(random_state=0), ElasticNet(random_state=0)]\n",
        "params = [{'clf__n_estimators': [800, 1000],'clf__max_depth': [6,8], 'clf__learning_rate': [0.1, 0.5]},\n",
        "          {},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0]},\n",
        "          {'clf__alpha': [0.1, 1.0], 'clf__l1_ratio': [0.5, 0.8]}]\n",
        "for mod, par in zip(models, params):\n",
        "    X_valid, y_valid = X_train2_chosen.copy(), y_train2_chosen.copy()\n",
        "    my_pipeline = Pipeline(steps=[('preprocessor', preprocess),\n",
        "                                  ('clf', mod)])\n",
        "    clf = GridSearchCV(estimator = my_pipeline,\n",
        "                       param_grid = par,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       n_jobs=-1,\n",
        "                       cv=5)\n",
        "    clf.fit(X_valid, y_valid)\n",
        "    print(f'\\nEstimator: {mod} \\nHyperparams: {clf.best_params_}, MAE(training): {-1 * clf.best_score_:.3f}\\n')\n",
        "\n",
        "## 최적화 LinearRegression 사용 및 데이터 출력\n",
        "new_pipeline = Pipeline(steps=[('preprocessor', preprocess),\n",
        "                              ('lR', LinearRegression())])\n",
        "linR = GridSearchCV(estimator = new_pipeline,\n",
        "                    param_grid = {},\n",
        "                    scoring='neg_mean_absolute_error',\n",
        "                    n_jobs=-1,\n",
        "                    cv=5)\n",
        "X_valid, y_valid = X_train2_chosen.copy(), y_train2_chosen.copy()\n",
        "linR.fit(X_valid, y_valid)\n",
        "print('\\nLinearRegression')\n",
        "for s in [X_test2_1, X_test2_2, X_test2_3]:\n",
        "    name = s.P_NAME.iloc[0]\n",
        "    pred = linR.best_estimator_.predict(s)\n",
        "    print(f'{name}\\n{pred}')\n",
        "\n",
        "X_test2_cum = (X_test2_1.append(X_test2_2, ignore_index=True)).append(X_test2_3, ignore_index=True)    \n",
        "pred = linR.predict(X_test2_cum)\n",
        "X_test2_cum['P_PRICE'] = pred\n",
        "X_test2_cum.REG_DATE = pd.to_datetime(X_test2_cum.REG_DATE, format='%y%m%d').dt.date\n",
        "X_test2_cum.columns = ['품목', '상세품목', '날짜', '예측단가']\n",
        "X_test2_cum.to_excel('2021 빅콘테스트_데이터분석분야_챔피언리그_수산Biz_평가데이터_update_210831_예측(LR)_제거.xlsx',\n",
        "                     index=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:28:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "Estimator: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1) \n",
            "Hyperparams: {'clf__learning_rate': 0.1, 'clf__max_depth': 8, 'clf__n_estimators': 800}, MAE(training): 2.877\n",
            "\n",
            "\n",
            "Estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
            "Hyperparams: {}, MAE(training): 2.886\n",
            "\n",
            "\n",
            "Estimator: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "      normalize=False, random_state=0, solver='auto', tol=0.001) \n",
            "Hyperparams: {'clf__alpha': 1.0}, MAE(training): 2.869\n",
            "\n",
            "\n",
            "Estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
            "      normalize=False, positive=False, precompute=False, random_state=0,\n",
            "      selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1}, MAE(training): 2.839\n",
            "\n",
            "\n",
            "Estimator: ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
            "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False) \n",
            "Hyperparams: {'clf__alpha': 0.1, 'clf__l1_ratio': 0.8}, MAE(training): 2.853\n",
            "\n",
            "\n",
            "LinearRegression\n",
            "오징어\n",
            "[2.69473166 2.69470325 2.69467485 2.69464645 2.69433809 2.69430969\n",
            " 2.69428129 2.69425288 2.69393235 2.69390395 2.69387555 2.69384714\n",
            " 2.69381874 2.69351038 2.69348198 2.69345358 2.69342518 2.69311276\n",
            " 2.69308435 2.69305595 2.69302755 2.69299915 2.69269079 2.69266239\n",
            " 2.69263398 2.69260558]\n",
            "연어\n",
            "[14.43590154 14.43587314 14.43584474 14.43581634 14.43550797 14.43547957\n",
            " 14.43545117 14.43542277 14.43510224 14.43507383 14.43504543 14.43501703\n",
            " 14.43498863 14.43468027 14.43465186 14.43462346 14.43459506 14.43428264\n",
            " 14.43425424 14.43422584 14.43419744 14.43416903 14.43386067 14.43383227\n",
            " 14.43380387 14.43377547]\n",
            "흰다리새우\n",
            "[9.97764421 9.97761581 9.97758741 9.977559   9.97725064 9.97722224\n",
            " 9.97719384 9.97716544 9.9768449  9.9768165  9.9767881  9.9767597\n",
            " 9.9767313  9.97642293 9.97639453 9.97636613 9.97633773 9.97602531\n",
            " 9.97599691 9.97596851 9.9759401  9.9759117  9.97560334 9.97557494\n",
            " 9.97554654 9.97551814]\n"
          ]
        }
      ]
    }
  ]
}